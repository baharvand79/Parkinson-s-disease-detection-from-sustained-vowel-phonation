{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:13.375005Z",
     "start_time": "2025-08-28T10:51:11.832914Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:13.489928Z",
     "start_time": "2025-08-28T10:51:13.410817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONFIG_PATHS_FILE = pd.read_csv(r\"D:\\Datasets\\config_paths.csv\")\n",
    "CONFIG_PATHS_FILE"
   ],
   "id": "46f933d1afbc83d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                              data  \\\n",
       "0           Neurovoz_METADATA_FILE   \n",
       "1            Neurovoz_AUDIO_FOLDER   \n",
       "2               Neurovoz_BASE_PATH   \n",
       "3  Neurovoz_MODIFIED_METADATA_FILE   \n",
       "\n",
       "                                                path  \n",
       "0  D:\\Datasets\\Neurovoz_v3\\data\\metadata\\metadata...  \n",
       "1                D:\\Datasets\\Neurovoz_v3\\data\\audios  \n",
       "2                            D:\\Datasets\\Neurovoz_v3  \n",
       "3  D:\\Datasets\\Neurovoz_v3\\data\\metadata\\metadata...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neurovoz_METADATA_FILE</td>\n",
       "      <td>D:\\Datasets\\Neurovoz_v3\\data\\metadata\\metadata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neurovoz_AUDIO_FOLDER</td>\n",
       "      <td>D:\\Datasets\\Neurovoz_v3\\data\\audios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neurovoz_BASE_PATH</td>\n",
       "      <td>D:\\Datasets\\Neurovoz_v3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neurovoz_MODIFIED_METADATA_FILE</td>\n",
       "      <td>D:\\Datasets\\Neurovoz_v3\\data\\metadata\\metadata...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:13.575718Z",
     "start_time": "2025-08-28T10:51:13.561111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paths = CONFIG_PATHS_FILE['path']\n",
    "tmp_paths = []\n",
    "for p in paths:\n",
    "    tmp_paths.append(p.replace(\"\\\\\", \"/\"))\n",
    "CONFIG_PATHS_FILE['path'] = tmp_paths\n",
    "del tmp_paths, p, paths\n",
    "\n",
    "Neurovoz_METADATA_FILE = CONFIG_PATHS_FILE[CONFIG_PATHS_FILE['data'] == \"Neurovoz_METADATA_FILE\"]['path'].iloc[0]\n",
    "print(\"Neurovoz_METADATA_FILE: \", Neurovoz_METADATA_FILE)\n",
    "Neurovoz_AUDIO_FOLDER = CONFIG_PATHS_FILE[CONFIG_PATHS_FILE['data'] == \"Neurovoz_AUDIO_FOLDER\"]['path'].iloc[0]\n",
    "print(\"Neurovoz_AUDIO_FOLDER: \", Neurovoz_AUDIO_FOLDER)\n",
    "Neurovoz_BASE_PATH = CONFIG_PATHS_FILE[CONFIG_PATHS_FILE['data'] == \"Neurovoz_BASE_PATH\"]['path'].iloc[0]\n",
    "print(\"Neurovoz_BASE_PATH: \", Neurovoz_BASE_PATH)\n",
    "Neurovoz_MODIFIED_METADATA_FILE = \\\n",
    "CONFIG_PATHS_FILE[CONFIG_PATHS_FILE['data'] == \"Neurovoz_MODIFIED_METADATA_FILE\"]['path'].iloc[0]\n",
    "print(\"Neurovoz_MODIFIED_METADATA_FILE: \", Neurovoz_MODIFIED_METADATA_FILE)\n"
   ],
   "id": "22d194bd995cd564",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurovoz_METADATA_FILE:  D:/Datasets/Neurovoz_v3/data/metadata/metadata.csv\n",
      "Neurovoz_AUDIO_FOLDER:  D:/Datasets/Neurovoz_v3/data/audios\n",
      "Neurovoz_BASE_PATH:  D:/Datasets/Neurovoz_v3\n",
      "Neurovoz_MODIFIED_METADATA_FILE:  D:/Datasets/Neurovoz_v3/data/metadata/metadata_modified.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:13.752731Z",
     "start_time": "2025-08-28T10:51:13.705490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seleted_subjects_df = pd.read_csv(os.path.join(os.getcwd(), \"selected_subjects_paper.csv\"))\n",
    "seleted_subjects_df"
   ],
   "id": "bf9dbd0262350d98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       ID Group      Date   Sex   Age             Diagnosis  Vocal tremor  \\\n",
       "0      34    HC   5/1/2016  1.0  77.0                normal             0   \n",
       "1      34    HC   5/1/2016  1.0  77.0                normal             0   \n",
       "2      34    HC   5/1/2016  1.0  77.0                normal             0   \n",
       "3      34    HC   5/1/2016  1.0  77.0                normal             0   \n",
       "4      34    HC   5/1/2016  1.0  77.0                normal             0   \n",
       "...   ...   ...        ...  ...   ...                   ...           ...   \n",
       "1690  117    PD  11/1/2017  0.0  70.0  enfermedad-parkinson             0   \n",
       "1691  117    PD  11/1/2017  0.0  70.0  enfermedad-parkinson             0   \n",
       "1692  117    PD  11/1/2017  0.0  70.0  enfermedad-parkinson             0   \n",
       "1693  117    PD  11/1/2017  0.0  70.0  enfermedad-parkinson             0   \n",
       "1694  117    PD  11/1/2017  0.0  70.0  enfermedad-parkinson             0   \n",
       "\n",
       "      Cephalic tremor  Mandibular tremor  Sialorrhoea  ...  \\\n",
       "0                   0                  0            0  ...   \n",
       "1                   0                  0            0  ...   \n",
       "2                   0                  0            0  ...   \n",
       "3                   0                  0            0  ...   \n",
       "4                   0                  0            0  ...   \n",
       "...               ...                ...          ...  ...   \n",
       "1690                0                  0            1  ...   \n",
       "1691                0                  0            1  ...   \n",
       "1692                0                  0            1  ...   \n",
       "1693                0                  0            1  ...   \n",
       "1694                0                  0            1  ...   \n",
       "\n",
       "      Date Evaluation Scales   Medication   Medication status  Occupation  \\\n",
       "0                         NaN          NaN                NaN     retired   \n",
       "1                         NaN          NaN                NaN     retired   \n",
       "2                         NaN          NaN                NaN     retired   \n",
       "3                         NaN          NaN                NaN     retired   \n",
       "4                         NaN          NaN                NaN     retired   \n",
       "...                       ...          ...                ...         ...   \n",
       "1690                      NaN          NaN                 ON     retired   \n",
       "1691                      NaN          NaN                 ON     retired   \n",
       "1692                      NaN          NaN                 ON     retired   \n",
       "1693                      NaN          NaN                 ON     retired   \n",
       "1694                      NaN          NaN                 ON     retired   \n",
       "\n",
       "      Fiber/VocalFolds      Observations Doctor  \\\n",
       "0        Not performed               NaN    NaN   \n",
       "1        Not performed               NaN    NaN   \n",
       "2        Not performed               NaN    NaN   \n",
       "3        Not performed               NaN    NaN   \n",
       "4        Not performed               NaN    NaN   \n",
       "...                ...               ...    ...   \n",
       "1690     Not performed  Same patient H54    NaN   \n",
       "1691     Not performed  Same patient H54    NaN   \n",
       "1692     Not performed  Same patient H54    NaN   \n",
       "1693     Not performed  Same patient H54    NaN   \n",
       "1694     Not performed  Same patient H54    NaN   \n",
       "\n",
       "                                                  Audio           filename  \\\n",
       "0     D:/Datasets/Neurovoz_v3/data/audios/HC_ABLANDA...  HC_ABLANDADA_0034   \n",
       "1     D:/Datasets/Neurovoz_v3/data/audios/HC_PIDIO_0...      HC_PIDIO_0034   \n",
       "2     D:/Datasets/Neurovoz_v3/data/audios/HC_BURRO_0...      HC_BURRO_0034   \n",
       "3     D:/Datasets/Neurovoz_v3/data/audios/HC_GANGA_0...      HC_GANGA_0034   \n",
       "4     D:/Datasets/Neurovoz_v3/data/audios/HC_MANGA_0...      HC_MANGA_0034   \n",
       "...                                                 ...                ...   \n",
       "1690  D:/Datasets/Neurovoz_v3/data/audios/PD_MANGA_0...      PD_MANGA_0117   \n",
       "1691  D:/Datasets/Neurovoz_v3/data/audios/PD_BURRO_0...      PD_BURRO_0117   \n",
       "1692  D:/Datasets/Neurovoz_v3/data/audios/PD_ACAMPAD...   PD_ACAMPADA_0117   \n",
       "1693  D:/Datasets/Neurovoz_v3/data/audios/PD_DIABLO_...     PD_DIABLO_0117   \n",
       "1694  D:/Datasets/Neurovoz_v3/data/audios/PD_SOMBRA_...     PD_SOMBRA_0117   \n",
       "\n",
       "           Type  \n",
       "0     ABLANDADA  \n",
       "1         PIDIO  \n",
       "2         BURRO  \n",
       "3         GANGA  \n",
       "4         MANGA  \n",
       "...         ...  \n",
       "1690      MANGA  \n",
       "1691      BURRO  \n",
       "1692   ACAMPADA  \n",
       "1693     DIABLO  \n",
       "1694     SOMBRA  \n",
       "\n",
       "[1695 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Vocal tremor</th>\n",
       "      <th>Cephalic tremor</th>\n",
       "      <th>Mandibular tremor</th>\n",
       "      <th>Sialorrhoea</th>\n",
       "      <th>...</th>\n",
       "      <th>Date Evaluation Scales</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Medication status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Fiber/VocalFolds</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Audio</th>\n",
       "      <th>filename</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_ABLANDA...</td>\n",
       "      <td>HC_ABLANDADA_0034</td>\n",
       "      <td>ABLANDADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_PIDIO_0...</td>\n",
       "      <td>HC_PIDIO_0034</td>\n",
       "      <td>PIDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_BURRO_0...</td>\n",
       "      <td>HC_BURRO_0034</td>\n",
       "      <td>BURRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_GANGA_0...</td>\n",
       "      <td>HC_GANGA_0034</td>\n",
       "      <td>GANGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_MANGA_0...</td>\n",
       "      <td>HC_MANGA_0034</td>\n",
       "      <td>MANGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>117</td>\n",
       "      <td>PD</td>\n",
       "      <td>11/1/2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>enfermedad-parkinson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>Same patient H54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/PD_MANGA_0...</td>\n",
       "      <td>PD_MANGA_0117</td>\n",
       "      <td>MANGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>117</td>\n",
       "      <td>PD</td>\n",
       "      <td>11/1/2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>enfermedad-parkinson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>Same patient H54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/PD_BURRO_0...</td>\n",
       "      <td>PD_BURRO_0117</td>\n",
       "      <td>BURRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>117</td>\n",
       "      <td>PD</td>\n",
       "      <td>11/1/2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>enfermedad-parkinson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>Same patient H54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/PD_ACAMPAD...</td>\n",
       "      <td>PD_ACAMPADA_0117</td>\n",
       "      <td>ACAMPADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>117</td>\n",
       "      <td>PD</td>\n",
       "      <td>11/1/2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>enfermedad-parkinson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>Same patient H54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/PD_DIABLO_...</td>\n",
       "      <td>PD_DIABLO_0117</td>\n",
       "      <td>DIABLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>117</td>\n",
       "      <td>PD</td>\n",
       "      <td>11/1/2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>enfermedad-parkinson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>Same patient H54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/PD_SOMBRA_...</td>\n",
       "      <td>PD_SOMBRA_0117</td>\n",
       "      <td>SOMBRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1695 rows × 25 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:14.876144Z",
     "start_time": "2025-08-28T10:51:14.868212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = seleted_subjects_df.copy()\n",
    "df.columns"
   ],
   "id": "88d5919e23f8b13f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Group', 'Date ', 'Sex', 'Age', 'Diagnosis', 'Vocal tremor',\n",
       "       'Cephalic tremor', 'Mandibular tremor', 'Sialorrhoea', 'Dysphagia',\n",
       "       'Hypophonic voice', 'Time Disease (years)', 'UPDRS scale',\n",
       "       'H-Y Stadium', 'Date Evaluation Scales ', 'Medication ',\n",
       "       'Medication status', 'Occupation', 'Fiber/VocalFolds', 'Observations',\n",
       "       'Doctor', 'Audio', 'filename', 'Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:15.287735Z",
     "start_time": "2025-08-28T10:51:15.281822Z"
    }
   },
   "cell_type": "code",
   "source": "df.rename(columns={'Group': 'Label', 'ID': 'Subject_ID'}, inplace=True)",
   "id": "8cbf11f917d322d5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:15.714866Z",
     "start_time": "2025-08-28T10:51:15.707887Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "f16c97b35e8c6dcf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Subject_ID', 'Label', 'Date ', 'Sex', 'Age', 'Diagnosis',\n",
       "       'Vocal tremor', 'Cephalic tremor', 'Mandibular tremor', 'Sialorrhoea',\n",
       "       'Dysphagia', 'Hypophonic voice', 'Time Disease (years)', 'UPDRS scale',\n",
       "       'H-Y Stadium', 'Date Evaluation Scales ', 'Medication ',\n",
       "       'Medication status', 'Occupation', 'Fiber/VocalFolds', 'Observations',\n",
       "       'Doctor', 'Audio', 'filename', 'Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:43.405806Z",
     "start_time": "2025-08-28T10:51:25.141760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 1: Imports and Global Configuration\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor, HubertModel\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupShuffleSplit\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "SAMPLE_RATE = 16000\n",
    "CLIP_DURATION = 5.0\n",
    "MAX_AUDIO_LEN = int(SAMPLE_RATE * CLIP_DURATION)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LR = 2e-5\n",
    "DROPOUT = 0.2\n",
    "MODEL_NAME = \"facebook/wav2vec2-base\" # Or \"facebook/hubert-base-ls960\"\n",
    "PATIENCE = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Setup complete. Using device: {DEVICE}\")\n",
    "\n",
    "print(f\"Loaded {len(df)} total audio samples.\")\n",
    "print(f\"Number of unique subjects: {df['Subject_ID'].nunique()}\")\n",
    "print(\"Value counts for labels:\")\n",
    "print(df['Label'].value_counts())\n",
    "df.head()"
   ],
   "id": "8a61f08a8e6ba4af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Setup complete. Using device: cpu\n",
      "Loaded 1695 total audio samples.\n",
      "Number of unique subjects: 107\n",
      "Value counts for labels:\n",
      "Label\n",
      "HC    867\n",
      "PD    828\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Subject_ID Label     Date   Sex   Age Diagnosis  Vocal tremor  \\\n",
       "0          34    HC  5/1/2016  1.0  77.0    normal             0   \n",
       "1          34    HC  5/1/2016  1.0  77.0    normal             0   \n",
       "2          34    HC  5/1/2016  1.0  77.0    normal             0   \n",
       "3          34    HC  5/1/2016  1.0  77.0    normal             0   \n",
       "4          34    HC  5/1/2016  1.0  77.0    normal             0   \n",
       "\n",
       "   Cephalic tremor  Mandibular tremor  Sialorrhoea  ...  \\\n",
       "0                0                  0            0  ...   \n",
       "1                0                  0            0  ...   \n",
       "2                0                  0            0  ...   \n",
       "3                0                  0            0  ...   \n",
       "4                0                  0            0  ...   \n",
       "\n",
       "   Date Evaluation Scales   Medication   Medication status  Occupation  \\\n",
       "0                      NaN          NaN                NaN     retired   \n",
       "1                      NaN          NaN                NaN     retired   \n",
       "2                      NaN          NaN                NaN     retired   \n",
       "3                      NaN          NaN                NaN     retired   \n",
       "4                      NaN          NaN                NaN     retired   \n",
       "\n",
       "   Fiber/VocalFolds Observations Doctor  \\\n",
       "0     Not performed          NaN    NaN   \n",
       "1     Not performed          NaN    NaN   \n",
       "2     Not performed          NaN    NaN   \n",
       "3     Not performed          NaN    NaN   \n",
       "4     Not performed          NaN    NaN   \n",
       "\n",
       "                                               Audio           filename  \\\n",
       "0  D:/Datasets/Neurovoz_v3/data/audios/HC_ABLANDA...  HC_ABLANDADA_0034   \n",
       "1  D:/Datasets/Neurovoz_v3/data/audios/HC_PIDIO_0...      HC_PIDIO_0034   \n",
       "2  D:/Datasets/Neurovoz_v3/data/audios/HC_BURRO_0...      HC_BURRO_0034   \n",
       "3  D:/Datasets/Neurovoz_v3/data/audios/HC_GANGA_0...      HC_GANGA_0034   \n",
       "4  D:/Datasets/Neurovoz_v3/data/audios/HC_MANGA_0...      HC_MANGA_0034   \n",
       "\n",
       "        Type  \n",
       "0  ABLANDADA  \n",
       "1      PIDIO  \n",
       "2      BURRO  \n",
       "3      GANGA  \n",
       "4      MANGA  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Vocal tremor</th>\n",
       "      <th>Cephalic tremor</th>\n",
       "      <th>Mandibular tremor</th>\n",
       "      <th>Sialorrhoea</th>\n",
       "      <th>...</th>\n",
       "      <th>Date Evaluation Scales</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Medication status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Fiber/VocalFolds</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Audio</th>\n",
       "      <th>filename</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_ABLANDA...</td>\n",
       "      <td>HC_ABLANDADA_0034</td>\n",
       "      <td>ABLANDADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_PIDIO_0...</td>\n",
       "      <td>HC_PIDIO_0034</td>\n",
       "      <td>PIDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_BURRO_0...</td>\n",
       "      <td>HC_BURRO_0034</td>\n",
       "      <td>BURRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_GANGA_0...</td>\n",
       "      <td>HC_GANGA_0034</td>\n",
       "      <td>GANGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>HC</td>\n",
       "      <td>5/1/2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>retired</td>\n",
       "      <td>Not performed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D:/Datasets/Neurovoz_v3/data/audios/HC_MANGA_0...</td>\n",
       "      <td>HC_MANGA_0034</td>\n",
       "      <td>MANGA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:50.789413Z",
     "start_time": "2025-08-28T10:51:50.768355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---\n",
    "# Cell 3: Definition of Core Components (Dataset, Loss, Model, and Functions)\n",
    "class ParkinsonDataset(Dataset):\n",
    "    def __init__(self, df, processor, augment=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        path = row['Audio']\n",
    "        try:\n",
    "            label = int(row['Label'])\n",
    "        except ValueError:\n",
    "            label_map = {\"HC\": 0, \"PD\": 1}\n",
    "            label = label_map.get(str(row['Label']).strip(), -1)\n",
    "        try:\n",
    "            waveform, sr = torchaudio.load(path)\n",
    "            if sr != SAMPLE_RATE:\n",
    "                waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "\n",
    "            waveform = torchaudio.transforms.Vad(sample_rate=SAMPLE_RATE)(waveform)\n",
    "            if waveform.numel() == 0:\n",
    "                waveform, _ = torchaudio.load(path)\n",
    "                if sr != SAMPLE_RATE: waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "\n",
    "            if waveform.size(1) > MAX_AUDIO_LEN:\n",
    "                waveform = waveform[:, :MAX_AUDIO_LEN]\n",
    "            elif waveform.size(1) < MAX_AUDIO_LEN:\n",
    "                waveform = torch.nn.functional.pad(waveform, (0, MAX_AUDIO_LEN - waveform.size(1)))\n",
    "\n",
    "            if self.augment:\n",
    "                waveform = F.lowpass_biquad(waveform, sample_rate=SAMPLE_RATE, cutoff_freq=3000)\n",
    "\n",
    "            inputs = self.processor(waveform.squeeze().numpy(), sampling_rate=SAMPLE_RATE, return_tensors=\"pt\")\n",
    "            return inputs.input_values.squeeze(0), label\n",
    "        except Exception:\n",
    "            return torch.zeros(MAX_AUDIO_LEN), -1\n",
    "\n",
    "class SupConLossWithHardScaling(nn.Module):\n",
    "    def __init__(self, temperature=0.07, scale_factor=1.5, base_temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.scale_factor = scale_factor\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        features = nn.functional.normalize(features, p=2, dim=1)\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        logits_mask = torch.ones_like(mask) - torch.eye(batch_size, device=device)\n",
    "        mask = mask * logits_mask\n",
    "        anchor_dot_contrast = torch.div(torch.matmul(features, features.T), self.temperature)\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        weights = torch.ones_like(logits)\n",
    "        negatives_only_logits = logits.clone()\n",
    "        negatives_only_logits[mask == 1] = -float('inf')\n",
    "        hardest_negative_indices = torch.argmax(negatives_only_logits, dim=1)\n",
    "        weights.scatter_(1, hardest_negative_indices.view(-1, 1), self.scale_factor)\n",
    "        exp_logits = torch.exp(logits) * logits_mask * weights\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-6)\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "class PDModel(nn.Module):\n",
    "    def __init__(self, base_model_name, output_dim=2):\n",
    "        super().__init__()\n",
    "        if \"wav2vec\" in base_model_name: self.encoder = Wav2Vec2Model.from_pretrained(base_model_name)\n",
    "        else: self.encoder = HubertModel.from_pretrained(base_model_name)\n",
    "        embedding_dim = self.encoder.config.hidden_size\n",
    "        self.classifier = nn.Sequential(nn.Linear(embedding_dim, 64), nn.ReLU(), nn.Dropout(DROPOUT), nn.Linear(64, output_dim))\n",
    "        self.projection = nn.Sequential(nn.Linear(embedding_dim, 32), nn.ReLU(), nn.Dropout(DROPOUT))\n",
    "\n",
    "    def forward(self, input_values):\n",
    "        pooled = self.encoder(input_values).last_hidden_state.mean(dim=1)\n",
    "        proj = self.projection(pooled)\n",
    "        logits = self.classifier(pooled.detach())\n",
    "        return logits, proj\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, ce_loss_fn, supcon_loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in dataloader:\n",
    "        if isinstance(y, torch.Tensor) and -1 in y: continue\n",
    "        if isinstance(y, (tuple, list)) and -1 in y: continue\n",
    "\n",
    "        # FIX: Explicitly convert labels (y) to a tensor to handle cases\n",
    "        # where the dataloader yields a tuple of numbers instead of a tensor.\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long, device=DEVICE)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, proj = model(x)\n",
    "        loss = ce_loss_fn(logits, y_tensor) + supcon_loss_fn(proj, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            if isinstance(y, torch.Tensor) and -1 in y: continue\n",
    "            if isinstance(y, (tuple, list)) and -1 in y: continue\n",
    "\n",
    "            # FIX: Explicitly convert labels to a numpy array for scikit-learn.\n",
    "            y_numpy = torch.tensor(y).numpy()\n",
    "            x = x.to(DEVICE)\n",
    "\n",
    "            logits, _ = model(x)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y_numpy)\n",
    "\n",
    "    if not all_labels: return 0, 0, 0, 0, 0\n",
    "\n",
    "    # Robustness: Handle cases where a fold has only one class, which crashes confusion_matrix.\n",
    "    if len(np.unique(all_labels)) < 2:\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        return acc, 0, 0, 0, 0 # Other metrics are not well-defined here\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds, labels=[0, 1]).ravel()\n",
    "    return (\n",
    "        accuracy_score(all_labels, all_preds),\n",
    "        f1_score(all_labels, all_preds, zero_division=0),\n",
    "        precision_score(all_labels, all_preds, zero_division=0),\n",
    "        recall_score(all_labels, all_preds, zero_division=0),\n",
    "        tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ Core components defined successfully.\")"
   ],
   "id": "a080e4eb5fbbe2ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Core components defined successfully.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:51:54.996709Z",
     "start_time": "2025-08-28T10:51:54.983282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---\n",
    "# Cell 4: Speaker-Independent Train/Test Split\n",
    "print(\"\\nSplitting data into 80% train/validation and 20% test sets (speaker-independent)...\")\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_val_idx, test_idx = next(gss.split(df, df['Label'], df['Subject_ID']))\n",
    "\n",
    "train_val_df = df.iloc[train_val_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "print(f\"\\nTrain/Val set: {len(train_val_df)} samples from {train_val_df['Subject_ID'].nunique()} speakers.\")\n",
    "print(f\"Test set:      {len(test_df)} samples from {test_df['Subject_ID'].nunique()} speakers.\")\n",
    "\n",
    "train_speakers = set(train_val_df['Subject_ID'])\n",
    "test_speakers = set(test_df['Subject_ID'])\n",
    "assert len(train_speakers.intersection(test_speakers)) == 0, \"Speaker overlap detected!\"\n",
    "print(\"\\n✅ Verification complete: No speaker overlap between train/val and test sets.\")"
   ],
   "id": "1c76c9c2935c8081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into 80% train/validation and 20% test sets (speaker-independent)...\n",
      "\n",
      "Train/Val set: 1343 samples from 85 speakers.\n",
      "Test set:      352 samples from 22 speakers.\n",
      "\n",
      "✅ Verification complete: No speaker overlap between train/val and test sets.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T10:52:04.450987Z",
     "start_time": "2025-08-28T10:51:59.587918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---\n",
    "# Cell 5: Main 5-Fold Cross-Validation Training Loop\n",
    "print(\"\\nStarting 5-fold stratified, speaker-independent cross-validation...\")\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "sgkf = StratifiedGroupKFold(n_splits=5)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(train_val_df, train_val_df['Label'], train_val_df['Subject_ID'])):\n",
    "    print(f\"\\n{'='*20} FOLD {fold+1} {'='*20}\")\n",
    "\n",
    "    train_fold_df = train_val_df.iloc[train_idx]\n",
    "    val_fold_df = train_val_df.iloc[val_idx]\n",
    "\n",
    "    train_ds = ParkinsonDataset(train_fold_df, processor, augment=True)\n",
    "    val_ds = ParkinsonDataset(val_fold_df, processor, augment=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = PDModel(MODEL_NAME).to(DEVICE)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    supcon_loss = SupConLossWithHardScaling(scale_factor=1.5).to(DEVICE)\n",
    "\n",
    "    best_val_f1 = -1\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=f\"Fold {fold+1} Training\"):\n",
    "        train_loss = train_one_epoch(model, train_dl, optimizer, ce_loss, supcon_loss)\n",
    "        acc, f1, _, _, _ = evaluate(model, val_dl)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val F1: {f1:.4f} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_fold_{fold+1}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "    fold_results.append(best_val_f1)\n",
    "    print(f\"✅ Best F1 for Fold {fold+1}: {best_val_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\\nAverage CV F1 Score: {np.mean(fold_results):.4f} +/- {np.std(fold_results):.4f}\")\n"
   ],
   "id": "a6593e95b42fb36d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 5-fold stratified, speaker-independent cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bahar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\configuration_utils.py:334: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== FOLD 1 ====================\n",
      "\n",
      "==================== FOLD 2 ====================\n",
      "\n",
      "==================== FOLD 3 ====================\n",
      "\n",
      "==================== FOLD 4 ====================\n",
      "\n",
      "==================== FOLD 5 ====================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---\n",
    "# Cell 6: Final Evaluation on the Held-Out Test Set\n",
    "print(\"\\nEvaluating the best model on the held-out test set...\")\n",
    "\n",
    "best_fold_idx = np.argmax(fold_results)\n",
    "best_model_path = f\"best_model_fold_{best_fold_idx+1}.pth\"\n",
    "print(f\"Loading best model from Fold {best_fold_idx+1} (path: {best_model_path})\")\n",
    "\n",
    "final_model = PDModel(MODEL_NAME).to(DEVICE)\n",
    "final_model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\n",
    "\n",
    "test_ds = ParkinsonDataset(test_df, processor, augment=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "acc, f1, prec, sens, spec = evaluate(final_model, test_dl)\n",
    "\n",
    "print(\"\\n--- FINAL TEST SET PERFORMANCE ---\")\n",
    "print(f\"  {'Metric':<22} | {'Score':<10}\")\n",
    "print(f\"  {'-'*22} | {'-'*10}\")\n",
    "print(f\"  {'Accuracy':<22} | {acc:.4f}\")\n",
    "print(f\"  {'F1-Score':<22} | {f1:.4f}\")\n",
    "print(f\"  {'Precision':<22} | {prec:.4f}\")\n",
    "print(f\"  {'Sensitivity (Recall)':<22} | {sens:.4f}\")\n",
    "print(f\"  {'Specificity':<22} | {spec:.4f}\")\n",
    "print(\"------------------------------------\")"
   ],
   "id": "81fc2a4b84c0863b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
